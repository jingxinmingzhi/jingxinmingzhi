<div class="post">
            <h1 class="postTitle">
                
<a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/my8100/p/scrapyd-cluster-on-heroku.html">
    <span>如何免费创建云端爬虫集群</span>
    


</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                
    <div id="cnblogs_post_description" style="display: none">
        <img src="https://raw.githubusercontent.com/my8100/files/master/scrapyd-cluster-on-heroku/screenshots/network_topology.png" class="desc_img">
    </div>
<div id="cnblogs_post_body" class="blogpost-body ">
    <h2>在线体验</h2>
<p><a href="https://scrapydweb.herokuapp.com/" rel="nofollow">scrapydweb.herokuapp.com</a></p>
<h2><a id="user-content-网络拓扑图" class="anchor" href="https://github.com/my8100/scrapyd-cluster-on-heroku/blob/master/README_CN.md#%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91%E5%9B%BE"></a>网络拓扑图</h2>
<p><img src="https://img2018.cnblogs.com/blog/892328/201904/892328-20190405144148631-757290246.png" alt=""></p>
<h2><a id="user-content-注册帐号" class="anchor" href="https://github.com/my8100/scrapyd-cluster-on-heroku/blob/master/README_CN.md#%E6%B3%A8%E5%86%8C%E5%B8%90%E5%8F%B7"></a>注册帐号</h2>
<ol>
<li>Heroku</li>
</ol>
<p>访问 <a href="https://signup.heroku.com/" rel="nofollow">heroku.com</a> 注册免费账号（注册页面需要调用 google recaptcha 人机验证，登录页面也需要<strong>科学地进行上网</strong>，访问 app 运行页面则没有该问题），免费账号最多可以<strong>创建和运行5个 app</strong>。</p>
<p><img src="https://img2018.cnblogs.com/blog/892328/201904/892328-20190405145316985-1552219166.png" alt=""></p>
<ol start="2">
<li>Redis Labs（可选）</li>
</ol>
<p>访问 <a href="https://redislabs.com/" rel="nofollow">redislabs.com</a> 注册免费账号，提供30MB 存储空间，用于下文通过 <a href="https://github.com/rmax/scrapy-redis">scrapy-redis</a> 实现分布式爬虫。</p>
<p><img src="https://img2018.cnblogs.com/blog/892328/201904/892328-20190405145340183-1787943396.png" alt=""></p>
<h2><a id="user-content-通过浏览器部署-heroku-app" class="anchor" href="https://github.com/my8100/scrapyd-cluster-on-heroku/blob/master/README_CN.md#%E9%80%9A%E8%BF%87%E6%B5%8F%E8%A7%88%E5%99%A8%E9%83%A8%E7%BD%B2-heroku-app"></a>通过浏览器部署 Heroku app</h2>
<ol>
<li>访问 <a href="https://github.com/my8100/scrapyd-cluster-on-heroku-scrapyd-app">my8100/scrapyd-cluster-on-heroku-scrapyd-app</a> 一键部署 Scrapyd app。（注意更新页面表单中 Redis 服务器的主机，端口和密码）</li>
<li>重复第1步完成4个 Scrapyd app 的部署，假设应用名称为  <span class="cnblogs_code">svr-<span style="color: #800080;">1</span></span> ,  <span class="cnblogs_code">svr-<span style="color: #800080;">2</span></span> ,  <span class="cnblogs_code">svr-<span style="color: #800080;">3</span></span>  和  <span class="cnblogs_code">svr-<span style="color: #800080;">4</span></span> </li>
<li>访问 <a href="https://github.com/my8100/scrapyd-cluster-on-heroku-scrapydweb-app">my8100/scrapyd-cluster-on-heroku-scrapydweb-app</a> 一键部署 ScrapydWeb app，取名  <span class="cnblogs_code">myscrapydweb</span> </li>
<li>（可选）点击 <a href="https://dashboard.heroku.com/apps/myscrapydweb/settings" rel="nofollow">dashboard.heroku.com/apps/myscrapydweb/settings</a> 页面中的 Reveal Config Vars 按钮相应添加更多 Scrapyd server，例如 KEY 为  <span class="cnblogs_code">SCRAPYD_SERVER_2</span> , VALUE 为  <span class="cnblogs_code">svr-<span style="color: #800080;">2</span>.herokuapp.com:<span style="color: #800080;">80</span>#group2</span> </li>
<li>访问 <a href="https://myscrapydweb.herokuapp.com/" rel="nofollow">myscrapydweb.herokuapp.com</a></li>
<li>跳转 <strong>部署和运行分布式爬虫</strong> 章节继续阅读。</li>
</ol>
<h2><a id="user-content-自定义部署" class="anchor" href="https://github.com/my8100/scrapyd-cluster-on-heroku/blob/master/README_CN.md#%E8%87%AA%E5%AE%9A%E4%B9%89%E9%83%A8%E7%BD%B2"></a>自定义部署</h2>
<h3><a id="user-content-安装工具" class="anchor" href="https://github.com/my8100/scrapyd-cluster-on-heroku/blob/master/README_CN.md#%E5%AE%89%E8%A3%85%E5%B7%A5%E5%85%B7"></a>安装工具</h3>
<ol>
<li><a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git" rel="nofollow">Git</a></li>
<li><a href="https://devcenter.heroku.com/articles/heroku-cli" rel="nofollow">Heroku CLI</a></li>
<li><a href="https://pypi.org/project/redis/" rel="nofollow">Python client for Redis</a>：运行  <span class="cnblogs_code">pip <span style="color: #0000ff;">install</span> redis</span>  命令即可。</li>
</ol>
<h3><a id="user-content-下载配置文件" class="anchor" href="https://github.com/my8100/scrapyd-cluster-on-heroku/blob/master/README_CN.md#%E4%B8%8B%E8%BD%BD%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"></a>下载配置文件</h3>
<p>新开一个命令行提示符：</p>
<div class="cnblogs_code">
<pre>git clone https:<span style="color: #008000;">//</span><span style="color: #008000;">github.com/my8100/scrapyd-cluster-on-heroku</span>
cd scrapyd-cluster-on-heroku</pre>
</div>
<p> </p>
<h3><a id="user-content-登录-heroku" class="anchor" href="https://github.com/my8100/scrapyd-cluster-on-heroku/blob/master/README_CN.md#%E7%99%BB%E5%BD%95-heroku"></a>登录 Heroku</h3>
<div class="cnblogs_code">
<pre>heroku <span style="color: #0000ff;">login</span><span style="color: #000000;">
# outputs:
# heroku: Press any key to open up the browser to </span><span style="color: #0000ff;">login</span><span style="color: #000000;"> or q to exit:
# Opening browser to https:</span><span style="color: #008000;">//</span><span style="color: #008000;">cli-auth.heroku.com/auth/browser/12345-abcde</span>
# Logging <span style="color: #0000ff;">in</span>... <span style="color: #0000ff;">done</span><span style="color: #000000;">
# Logged </span><span style="color: #0000ff;">in</span> as username@gmail.com</pre>
</div>
<p> </p>
<h3><a id="user-content-创建-scrapyd-集群" class="anchor" href="https://github.com/my8100/scrapyd-cluster-on-heroku/blob/master/README_CN.md#%E5%88%9B%E5%BB%BA-scrapyd-%E9%9B%86%E7%BE%A4"></a>创建 Scrapyd 集群</h3>
<ol>
<li>新建 Git 仓库</li>
</ol>
<div class="cnblogs_code">
<pre><span style="color: #000000;">cd scrapyd
git init
# explore and update the files </span><span style="color: #0000ff;">if</span><span style="color: #000000;"> needed
git status
git add .
git commit </span>-a -m <span style="color: #800000;">"</span><span style="color: #800000;">first commit</span><span style="color: #800000;">"</span><span style="color: #000000;">
git status</span></pre>
</div>
<p> </p>
<ol start="2">
<li>部署 Scrapyd app</li>
</ol>
<div class="cnblogs_code">
<pre>heroku apps:create svr-<span style="color: #800080;">1</span><span style="color: #000000;">
heroku git:remote </span>-a svr-<span style="color: #800080;">1</span><span style="color: #000000;">
git remote </span>-<span style="color: #000000;">v
git push heroku master
heroku logs </span>--<span style="color: #0000ff;">tail</span><span style="color: #000000;">
# Press ctrl</span>+<span style="color: #000000;">c to stop logs outputting
# Visit https:</span><span style="color: #008000;">//</span><span style="color: #008000;">svr-1.herokuapp.com</span></pre>
</div>
<p> </p>
<ol start="3">
<li>
<p>添加环境变量</p>
<ul>
<li>设置时区</li>
</ul>
<div class="cnblogs_code">
<pre># python -c <span style="color: #800000;">"</span><span style="color: #800000;">import tzlocal; print(tzlocal.get_localzone())</span><span style="color: #800000;">"</span><span style="color: #000000;">
heroku config:set TZ</span>=Asia/<span style="color: #000000;">Shanghai
# heroku config:get TZ</span></pre>
</div>
<p> </p>
<ul>
<li>添加 Redis 账号（可选，详见 <em>scrapy_redis_demo_project.zip</em> 中的 <em>settings.py</em>）</li>
</ul>
<div class="cnblogs_code">
<pre>heroku config:set REDIS_HOST=your-redis-<span style="color: #000000;">host
heroku config:set REDIS_PORT</span>=your-redis-<span style="color: #000000;">port
heroku config:set REDIS_PASSWORD</span>=your-redis-password</pre>
</div>
<p> </p>
</li>
<li>
<p>重复上述第2步和第3步完成余下三个 Scrapyd app 的部署和配置： <span class="cnblogs_code">svr-<span style="color: #800080;">2</span></span> ， <span class="cnblogs_code">svr-<span style="color: #800080;">3</span></span>  和  <span class="cnblogs_code">svr-<span style="color: #800080;">4</span></span> </p>
</li>
</ol>
<h3><a id="user-content-创建-scrapydweb-app" class="anchor" href="https://github.com/my8100/scrapyd-cluster-on-heroku/blob/master/README_CN.md#%E5%88%9B%E5%BB%BA-scrapydweb-app"></a>创建 ScrapydWeb app</h3>
<ol>
<li>新建 Git 仓库</li>
</ol>
<div class="cnblogs_code">
<pre><span style="color: #000000;">cd ..
cd scrapydweb
git init
# explore and update the files </span><span style="color: #0000ff;">if</span><span style="color: #000000;"> needed
git status
git add .
git commit </span>-a -m <span style="color: #800000;">"</span><span style="color: #800000;">first commit</span><span style="color: #800000;">"</span><span style="color: #000000;">
git status</span></pre>
</div>
<p> </p>
<ol start="2">
<li>部署 ScrapydWeb app</li>
</ol>
<div class="cnblogs_code">
<pre><span style="color: #000000;">heroku apps:create myscrapydweb
heroku git:remote </span>-<span style="color: #000000;">a myscrapydweb
git remote </span>-<span style="color: #000000;">v
git push heroku master</span></pre>
</div>
<p> </p>
<ol start="3">
<li>
<p>添加环境变量</p>
<ul>
<li>设置时区</li>
</ul>
<div class="cnblogs_code">
<pre>heroku config:set TZ=Asia/Shanghai</pre>
</div>
<p> </p>
<ul>
<li>添加 Scrapyd server（详见 <em>scrapydweb</em> 目录下的 <em>scrapydweb_settings_v8.py</em>）</li>
</ul>
<div class="cnblogs_code">
<pre>heroku config:set SCRAPYD_SERVER_1=svr-<span style="color: #800080;">1</span>.herokuapp.com:<span style="color: #800080;">80</span><span style="color: #000000;">
heroku config:set SCRAPYD_SERVER_2</span>=svr-<span style="color: #800080;">2</span>.herokuapp.com:<span style="color: #800080;">80</span><span style="color: #000000;">#group1
heroku config:set SCRAPYD_SERVER_3</span>=svr-<span style="color: #800080;">3</span>.herokuapp.com:<span style="color: #800080;">80</span><span style="color: #000000;">#group1
heroku config:set SCRAPYD_SERVER_4</span>=svr-<span style="color: #800080;">4</span>.herokuapp.com:<span style="color: #800080;">80</span>#group2</pre>
</div>
<p> </p>
</li>
<li>
<p>访问 <a href="https://myscrapydweb.herokuapp.com/" rel="nofollow">myscrapydweb.herokuapp.com</a> </p>
</li>
</ol>
<p>　　<img src="https://img2018.cnblogs.com/blog/892328/201904/892328-20190405144919207-313578767.png" alt=""></p>
<h2><a id="user-content-部署和运行分布式爬虫" class="anchor" href="https://github.com/my8100/scrapyd-cluster-on-heroku/blob/master/README_CN.md#%E9%83%A8%E7%BD%B2%E5%92%8C%E8%BF%90%E8%A1%8C%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB"></a>部署和运行分布式爬虫</h2>
<ol>
<li>上传 demo 项目，即 <em>scrapyd-cluster-on-heroku</em> 目录下的压缩文档 <em>scrapy_redis_demo_project.zip</em></li>
<li>将种子请求推入  <span class="cnblogs_code">mycrawler:start_urls</span>  触发爬虫并查看结果</li>
</ol>
<div class="cnblogs_code">
<pre>In [1]: <span style="color: #0000ff;">import</span> redis  <span style="color: #008000;">#</span><span style="color: #008000;"> pip install redis</span>
<span style="color: #000000;">
In [</span>2]: r = redis.Redis(host=<span style="color: #800000;">'</span><span style="color: #800000;">your-redis-host</span><span style="color: #800000;">'</span>, port=your-redis-port, password=<span style="color: #800000;">'</span><span style="color: #800000;">your-redis-password</span><span style="color: #800000;">'</span><span style="color: #000000;">)

In [</span>3]: r.delete(<span style="color: #800000;">'</span><span style="color: #800000;">mycrawler_redis:requests</span><span style="color: #800000;">'</span>, <span style="color: #800000;">'</span><span style="color: #800000;">mycrawler_redis:dupefilter</span><span style="color: #800000;">'</span>, <span style="color: #800000;">'</span><span style="color: #800000;">mycrawler_redis:items</span><span style="color: #800000;">'</span><span style="color: #000000;">)
Out[</span>3<span style="color: #000000;">]: 0

In [</span>4]: r.lpush(<span style="color: #800000;">'</span><span style="color: #800000;">mycrawler:start_urls</span><span style="color: #800000;">'</span>, <span style="color: #800000;">'</span><span style="color: #800000;">http://books.toscrape.com</span><span style="color: #800000;">'</span>, <span style="color: #800000;">'</span><span style="color: #800000;">http://quotes.toscrape.com</span><span style="color: #800000;">'</span><span style="color: #000000;">)
Out[</span>4]: 2

<span style="color: #008000;">#</span><span style="color: #008000;"> wait for a minute</span>
In [5]: r.lrange(<span style="color: #800000;">'</span><span style="color: #800000;">mycrawler_redis:items</span><span style="color: #800000;">'</span>, 0, 1<span style="color: #000000;">)
Out[</span>5<span style="color: #000000;">]:
[b</span><span style="color: #800000;">'</span><span style="color: #800000;">{"url": "http://quotes.toscrape.com/", "title": "Quotes to Scrape", "hostname": "d6cf94d5-324e-4def-a1ab-e7ee2aaca45a", "crawled": "2019-04-02 03:42:37", "spider": "mycrawler_redis"}</span><span style="color: #800000;">'</span><span style="color: #000000;">,
 b</span><span style="color: #800000;">'</span><span style="color: #800000;">{"url": "http://books.toscrape.com/index.html", "title": "All products | Books to Scrape - Sandbox", "hostname": "d6cf94d5-324e-4def-a1ab-e7ee2aaca45a", "crawled": "2019-04-02 03:42:37", "spider": "mycrawler_redis"}</span><span style="color: #800000;">'</span>]</pre>
</div>
<p> </p>
<p> </p>
<p><img src="https://img2018.cnblogs.com/blog/892328/201904/892328-20190405145134824-1004981760.gif" alt=""></p>
<h2><a id="user-content-总结" class="anchor" href="https://github.com/my8100/scrapyd-cluster-on-heroku/blob/master/README_CN.md#%E6%80%BB%E7%BB%93"></a>总结</h2>
<ul>
<li>优点
<ul>
<li>免费</li>
<li>可以爬 Google 等外网</li>
<li>可扩展（借助于 <a href="https://github.com/my8100/scrapydweb">ScrapydWeb</a>）</li>
</ul>
</li>
<li>缺点
<ul>
<li>注册和登录需要科学地进行上网</li>
<li>Heroku app 每天至少自动重启一次并且重置所有文件，因此需要外接数据库保存数据，详见 <a href="https://devcenter.heroku.com/articles/dynos#restarting" rel="nofollow">devcenter.heroku.com</a></li>
</ul>
</li>
</ul>
<h2>GitHub 开源</h2>
<p><a href="https://github.com/my8100/scrapyd-cluster-on-heroku/blob/master/README_CN.md" target="_blank">my8100/scrapyd-cluster-on-</a>heroku</p>
<p> </p>
</div>
<div id="MySignature"></div>
<div class="clear"></div>
<div id="blog_post_info_block">
    <div id="blog_post_info"></div>
    <div class="clear"></div>
    <div id="post_next_prev"></div>
</div>
            </div>
            <div class="postDesc">posted @ 
<span id="post-date">2019-04-05 15:10</span> 
<a href="https://www.cnblogs.com/my8100/">my8100</a> 
阅读(<span id="post_view_count">...</span>) 
评论(<span id="post_comment_count">...</span>) 
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=10658782" rel="nofollow">编辑</a> 
<a href="javascript:void(0)" onclick="AddToWz(10658782);return false;">收藏</a></div>
        </div>